{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e48866",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25791a74",
   "metadata": {},
   "source": [
    "## 1. Import Data and Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b080dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Modelling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45079ad",
   "metadata": {},
   "source": [
    "#### Import the CSV Data as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11c6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/stroke.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6672f2e",
   "metadata": {},
   "source": [
    "## 2. Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74267da4",
   "metadata": {},
   "source": [
    "### 2.1. Remove and Combine Categories in a Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb794d72",
   "metadata": {},
   "source": [
    "From the EDA, we found that the *\"Other\"* category in the **Age** feature is extremely rare with just 1 record. Itâ€™s generally a good idea to remove or combine with male or female categories. We have decided to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5878a8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "Female    2994\n",
      "Male      2115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df[df['gender'] != 'Other']\n",
    "print(df['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4b7841",
   "metadata": {},
   "source": [
    "Combining rare categories in a categorical column is a good way to reduce the number of dummy variables when doing one-hot encoding. This helps simplify the model and avoid creating too many sparse features.\n",
    "\n",
    "From the EDA, the *\"Never_worked\"* category in the **work_type** feature rare with jush 22 record. One approach is to combine *children* and *never_worked* categories together and label it as \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62cb16f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- work_type variable before feature engineering: ----\n",
      " work_type\n",
      "Private          2924\n",
      "Self-employed     819\n",
      "children          687\n",
      "Govt_job          657\n",
      "Never_worked       22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- work_type variable after feature engineering: ----\n",
      " work_type\n",
      "Private          2924\n",
      "Self-employed     819\n",
      "Other             709\n",
      "Govt_job          657\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- work_type variable before feature engineering: ----\\n {df['work_type'].value_counts()}\")\n",
    "df['work_type'] = df['work_type'].replace(['Never_worked', 'children'], 'Other')\n",
    "print(f\"\\n--- work_type variable after feature engineering: ----\\n {df['work_type'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f303b",
   "metadata": {},
   "source": [
    "### 2.2. Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778502c3",
   "metadata": {},
   "source": [
    "We have 201 missing value in the **bmi**. Since **bmi** feature has an skewed distribution *Median* is better choice for data imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d9cef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- The number of Missing values in the bmi before data imputation: 201 ---- \n",
      "--- The number of Missing values in the bmi after data imputation: 0 ---- \n"
     ]
    }
   ],
   "source": [
    "print(f\"--- The number of Missing values in the bmi before data imputation: {df['bmi'].isna().sum()} ---- \")\n",
    "df['bmi'] = df['bmi'].fillna(df['bmi'].median())\n",
    "print(f\"--- The number of Missing values in the bmi after data imputation: {df['bmi'].isna().sum()} ---- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef5fea",
   "metadata": {},
   "source": [
    "### 2.3. Preparing X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9972cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id'], inplace=True)\n",
    "X = df.drop(columns=['stroke'],axis=1)\n",
    "y = df['stroke']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf26b83",
   "metadata": {},
   "source": [
    "### 2.4. Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b101214",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['age', 'bmi', 'avg_glucose_level']\n",
    "binary_features = ['gender', 'ever_married', 'Residence_type']\n",
    "categorical_features = ['work_type', 'smoking_status']\n",
    "\n",
    "# Identify passthrough columns\n",
    "all_columns = X.columns.tolist()\n",
    "used_columns = numerical_features + binary_features + categorical_features\n",
    "passthrough_columns = [col for col in all_columns if col not in used_columns]\n",
    "\n",
    "\n",
    "# Transformers\n",
    "numeric_transformer = StandardScaler()\n",
    "binary_transformer = OrdinalEncoder()\n",
    "categorical_transformer = OneHotEncoder(drop='first', sparse_output=False)\n",
    "\n",
    "# ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('bin', binary_transformer, binary_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d21e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "all_features = numerical_features + binary_features + list(cat_features) + passthrough_columns\n",
    "\n",
    "# To DataFrame\n",
    "X_transformed = pd.DataFrame(X_transformed, columns=all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f00eb",
   "metadata": {},
   "source": [
    "### 2.5. Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5c4e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3576, 14), (1533, 14))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed,y,test_size=0.3,random_state=42, stratify=y)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14cd383",
   "metadata": {},
   "source": [
    "### 2.6. Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63870091",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd80317",
   "metadata": {},
   "source": [
    "## 3. Create an Evaluate Function to give all metrics after model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c247bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return acc, precision, recall, f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79ccb8e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7436\n",
      "- Precision: 0.1411\n",
      "- Recall (Sensitivity): 0.8391\n",
      "- F1 Score: 0.2415\n",
      "----------------------------------\n",
      "Model performance for Test set:\n",
      "- Accuracy: 0.7352\n",
      "- Precision: 0.1314\n",
      "- Recall (Sensitivity): 0.7867\n",
      "- F1 Score: 0.2252\n",
      "Confusion Matrix:\n",
      " [[1068  390]\n",
      " [  16   59]]\n",
      "========================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall (Sensitivity): 1.0000\n",
      "- F1 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set:\n",
      "- Accuracy: 0.9191\n",
      "- Precision: 0.0984\n",
      "- Recall (Sensitivity): 0.0800\n",
      "- F1 Score: 0.0882\n",
      "Confusion Matrix:\n",
      " [[1403   55]\n",
      " [  69    6]]\n",
      "========================================\n",
      "\n",
      "\n",
      "Random Forest Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall (Sensitivity): 1.0000\n",
      "- F1 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set:\n",
      "- Accuracy: 0.9511\n",
      "- Precision: 0.0000\n",
      "- Recall (Sensitivity): 0.0000\n",
      "- F1 Score: 0.0000\n",
      "Confusion Matrix:\n",
      " [[1458    0]\n",
      " [  75    0]]\n",
      "========================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9530\n",
      "- Precision: 0.6875\n",
      "- Recall (Sensitivity): 0.0632\n",
      "- F1 Score: 0.1158\n",
      "----------------------------------\n",
      "Model performance for Test set:\n",
      "- Accuracy: 0.9452\n",
      "- Precision: 0.0000\n",
      "- Recall (Sensitivity): 0.0000\n",
      "- F1 Score: 0.0000\n",
      "Confusion Matrix:\n",
      " [[1449    9]\n",
      " [  75    0]]\n",
      "========================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9994\n",
      "- Precision: 1.0000\n",
      "- Recall (Sensitivity): 0.9885\n",
      "- F1 Score: 0.9942\n",
      "----------------------------------\n",
      "Model performance for Test set:\n",
      "- Accuracy: 0.9419\n",
      "- Precision: 0.2667\n",
      "- Recall (Sensitivity): 0.1067\n",
      "- F1 Score: 0.1524\n",
      "Confusion Matrix:\n",
      " [[1436   22]\n",
      " [  67    8]]\n",
      "========================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9773\n",
      "- Precision: 1.0000\n",
      "- Recall (Sensitivity): 0.5345\n",
      "- F1 Score: 0.6966\n",
      "----------------------------------\n",
      "Model performance for Test set:\n",
      "- Accuracy: 0.9472\n",
      "- Precision: 0.2500\n",
      "- Recall (Sensitivity): 0.0400\n",
      "- F1 Score: 0.0690\n",
      "Confusion Matrix:\n",
      " [[1449    9]\n",
      " [  72    3]]\n",
      "========================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced'),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(class_weight='balanced'),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBRegressor\": XGBClassifier(), \n",
    "    \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "f1_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    print(name)\n",
    "    model_list.append(name)\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(f\"- Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"- Precision: {train_precision:.4f}\")\n",
    "    print(f\"- Recall (Sensitivity): {train_recall:.4f}\")\n",
    "    print(f\"- F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "    print('----------------------------------')\n",
    "\n",
    "    print('Model performance for Test set:')\n",
    "    print(f\"- Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"- Precision: {test_precision:.4f}\")\n",
    "    print(f\"- Recall (Sensitivity): {test_recall:.4f}\")\n",
    "    print(f\"- F1 Score: {test_f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", test_cm)\n",
    "\n",
    "    f1_list.append(test_f1)\n",
    "\n",
    "    print('='*40)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06480b5a",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0159e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.225191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.152381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Name        f1\n",
       "0       Logistic Regression  0.225191\n",
       "4              XGBRegressor  0.152381\n",
       "1             Decision Tree  0.088235\n",
       "5    CatBoosting Classifier  0.068966\n",
       "3    K-Neighbors Classifier  0.000000\n",
       "2  Random Forest Classifier  0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list, f1_list)), columns=['Model Name', 'f1']).sort_values(by=[\"f1\"],ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
